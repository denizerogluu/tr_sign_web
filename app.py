import streamlit as st
import torch
import detect
from PIL import Image
from io import *
import glob
from datetime import datetime
import os
import wget
import time




def imageInput(device, src):
    if src == 'Kendim gÃ¶rÃ¼ntÃ¼ yÃ¼kleyeceÄŸim':
        image_file = st.file_uploader("Bir gÃ¶rÃ¼ntÃ¼ yÃ¼kleyiniz", type=['png', 'jpeg', 'jpg'])
        col1, col2 = st.columns(2)
        if image_file is not None:
            img = Image.open(image_file)
            with col1:
                st.image(img, caption='YÃ¼klenen GÃ¶rÃ¼ntÃ¼', use_column_width='always')
            ts = datetime.timestamp(datetime.now())
            imgpath = os.path.join('data/uploads', str(ts) + image_file.name)
            outputpath = 'C:/Users/SBK/Desktop/tr_sign_web/data/outputs/'+os.path.basename(image_file)
            with open(imgpath, mode="wb") as f:
                f.write(image_file.getbuffer())

            # call Model prediction--
           
            model = torch.hub.load('ultralytics/yolov5', 'custom', path='models/last.pt', force_reload=True)
            model.cuda() if device == 'cuda' else model.cpu()
            pred = model(imgpath)
            pred.render()  # render bbox in image
            for im in pred.ims:
                im_base64 = Image.fromarray(im)
                im_base64.save(outputpath)

            # --Display predicton

            img_ = Image.open(outputpath)
            with col2:
                st.image(img_, caption='MODEL Ã‡IKTISI', use_column_width='always')

    elif src == 'Test veri kÃ¼mesi':
        # Image selector slider
        test_images = os.listdir('data/images/')
        test_image = st.selectbox('LÃ¼tfen bir gÃ¶rÃ¼ntÃ¼ seÃ§iniz.', test_images)
        image_file = 'data/images/' + test_image
        submit = st.button("BAÅLAT!")
        col1, col2 = st.columns(2)
        with col1:
            img = Image.open(image_file)
            st.image(img, caption='SeÃ§ilen GÃ¶rÃ¼ntÃ¼', use_column_width='always')
        with col2:
            if image_file is not None and submit:
                # call Model prediction--
                model = torch.hub.load('ultralytics/yolov5', 'custom', path='models/last.pt', force_reload=True)
                pred = model(image_file)
                pred.render()  # render bbox in image
                for im in pred.ims:
                    im_base64 = Image.fromarray(im)
                    im_base64.save(r'C:\Users\SBK\Desktop\tr_sign_web\data\outputs\\'+os.path.basename(image_file))
                    # --Display predicton
                    img_ = Image.open(os.path.join(r'C:\Users\SBK\Desktop\tr_sign_web\data\outputs\\'+os.path.basename(image_file)))
                    st.image(img_, caption='MODEL Ã‡IKTISI')





def main():
    # -- Sidebar
    st.sidebar.title('âš™ï¸SeÃ§enekler')
    datasrc = st.sidebar.radio("GÃ¶rÃ¼ntÃ¼yÃ¼ nereden seÃ§eceÄŸinizi giriniz.", ['Test veri kÃ¼mesi', 'Kendim gÃ¶rÃ¼ntÃ¼ yÃ¼kleyeceÄŸim'])

    # option = st.sidebar.radio("Select input type.", ['Image', 'Video'])
    '''if torch.cuda.is_available():
        deviceoption = st.sidebar.radio("Select compute Device.", ['cpu', 'cuda'], index=1)
    else:
        deviceoption = st.sidebar.radio("Select compute Device.", ['cpu', 'cuda'], index=0)'''
    # -- End of Sidebar

    st.header('âœ‹Nesne TanÄ±ma AlgoritmasÄ± Kullanarak TÃ¼rkÃ§e Ä°ÅŸaret Dili Tespit Etme')
    st.subheader('ğŸ‘ˆğŸ½SeÃ§enekleri SeÃ§iniz')
    st.sidebar.markdown("# TÃ¼rkÃ§e Ä°ÅŸaret Dili TanÄ±ma Projesi"
                        "## Ã–ZET:"
                        "**GÃ¼nlÃ¼k hayatta insanlar; fikirlerini, dÃ¼ÅŸÃ¼ncelerini ve yaÅŸadÄ±klarÄ±nÄ± Ã§evrelerindeki insanlara iletmek iÃ§in birbirleriyle etkileÅŸirler. AynÄ± dili konuÅŸan insanlar bazÄ± durumlarda dil kullanmadan da birtakÄ±m iÅŸaretlerle iletiÅŸim kurabilmektedirler. Ä°ÅŸitme engellilerin iletiÅŸim saÄŸlamak amacÄ±yla parmak, el, kol, yÃ¼z hareketlerini kullanarak oluÅŸturduÄŸu iÅŸaret dili, doÄŸal bir iletiÅŸim aracÄ±dÄ±r."
"Ne yazÄ±k ki Ã¼lkemizde iÅŸaret dilinin ihmal edilmesi; bu konuda sÃ¶zlÃ¼k, dil bilgisi, ders kitabÄ±, yardÄ±mcÄ± ders kitaplarÄ± ve malzemelerinin hazÄ±rlanmasÄ±, araÅŸtÄ±rmalar yapÄ±lmasÄ± yeterince teÅŸvik gÃ¶rmediÄŸi gibi ulusal iÅŸaret dilimizin yaygÄ±nlaÅŸtÄ±rÄ±lmasÄ±nÄ± da geciktirdi. BÃ¼tÃ¼n bu olumsuzluklarÄ±n yanÄ±nda okulumuzda ve Ã§evremizde yaptÄ±ÄŸÄ±mÄ±z araÅŸtÄ±rmalar sonucunda iÅŸaret dili bilgisine dair yÃ¼zdemizin dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶rdÃ¼k. Bu kapsamda Ã¶ncelikle bu konuda farkÄ±ndalÄ±ÄŸÄ± arttÄ±rmak adÄ±na okulumuzda iÅŸaret dili kullanÄ±mÄ±na yÃ¶nelik bir seminer dÃ¼zenledik. ArdÄ±ndan yaptÄ±ÄŸÄ±mÄ±z gÃ¶zlemlerde gÃ¶rdÃ¼k ki Ã¶ÄŸrencilerimizin bu konuda ilgi alaka ve farkÄ±ndalÄ±klarÄ± seminer Ã¶ncesine gÃ¶re, seminer sonrasÄ±nda artÄ±ÅŸ gÃ¶sterdi. Bunun Ã¼zerine iÅŸaret dili bilmeyen bir birey ile iÅŸitme engelli bir bireyin iletiÅŸimini nasÄ±l kuvvetlendirebiliriz sorusu Ã¼zerine bir proje hayal etmeye baÅŸladÄ±k. Ve dÃ¼ÅŸÃ¼ndÃ¼k ki nesne tanÄ±ma artÄ±k gÃ¼nlÃ¼k hayatÄ±n birÃ§ok alanÄ±na yerleÅŸmiÅŸ durumda. Teknolojinin sÃ¼rekli olarak geliÅŸmesi insanoÄŸlunun yaptÄ±ÄŸÄ± birÃ§ok iÅŸin bilgisayarlar tarafÄ±ndan yapÄ±lmasÄ±nÄ± saÄŸlamaktadÄ±r."
"Ä°ÅŸaret dili engelli insanlarÄ±n iletiÅŸim kurmasÄ±nda sÃ¶zel ifadelerin kullanÄ±lmasÄ± yerine bedensel ifadelerin kullanÄ±lmasÄ± esasÄ±na dayanÄ±r. Burada Ã¶nemli olan hangi iÅŸaretin ne anlama geldiÄŸini bir deÄŸiÅŸmezlik Ã§erÃ§evesinde ele almaktÄ±r. Bunu da nesne tanÄ±ma sistemleri kullanarak baÅŸarmak mÃ¼mkÃ¼ndÃ¼r. Ã–ncelikli olarak iÅŸaret dilinin temel hareketlerinin veritabanÄ±nÄ±n oluÅŸturulmasÄ± gerekir. Burada dikkat edilmesi gereken nokta veritabanÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼dÃ¼r. VeritabanÄ± ne Ã§ok kÃ¼Ã§Ã¼k ne de Ã§ok bÃ¼yÃ¼k olmalÄ±dÄ±r. Ã‡Ã¼nkÃ¼ veritabanÄ± kÄ±sÄ±tlÄ± kaldÄ±ÄŸÄ±nda hareketin sÄ±nÄ±flandÄ±rÄ±lmasÄ± zorlaÅŸacak. Ã‡ok bÃ¼yÃ¼k olduÄŸunda ise karar verme sÃ¼resi artacaÄŸÄ± gibi Ã§akÄ±ÅŸmalar meydana gelebilir.**")

    imageInput('cuda', datasrc)

if __name__ == '__main__':
    main()


